{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.models.semantic_kernel import SKChatCompletionAdapter\n",
    "from autogen_core.models import ModelFamily, UserMessage\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.anthropic import AnthropicChatCompletion, AnthropicChatPromptExecutionSettings\n",
    "from semantic_kernel.memory.null_memory import NullMemory\n",
    "\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichengwen/miniconda3/envs/task-decomp/lib/python3.10/site-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'orm_mode' has been renamed to 'from_attributes'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "sys.path.append('../..')\n",
    "from server.custom_types import MCT_Node\n",
    "import criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'criteria' from '/Users/shichengwen/Documents/Projects/TaskDecomposition/TaskDecomposition/server/evaluator/criteria.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-mini-2024-07-18': {'value': 0,\n",
       "  'reason': 'Entity extraction is a process that involves identifying and categorizing key information or entities from unstructured text. The complexity of this task depends on various factors, including the specific requirements of the project, the variety of entities to be extracted, and the context in which this task is being performed.\\n\\n1. **Definition of Entity Extraction**: The task is somewhat akin to Named Entity Recognition (NER), which typically involves recognizing names of people, organizations, locations, etc. This implies a clear area of focus.\\n\\n2. **Potential for Layered Concepts**: Depending on the application, entity extraction can involve multiple layers of complexity. For example, if it requires extracting not just names but also relationships, context, or performing sentiment analysis, it could cross into a more complex territory.\\n\\n3. **Multi-Step Reasoning**: If entity extraction involves developing custom models, incorporating different algorithms, or requires integration with other systems for tasks like sentiment analysis or classification, it increases complexity. \\n\\n4. **Tools Availability**: There are existing libraries and frameworks (like spaCy, NLTK, etc.) that simplify entity extraction, but the complexity can rise if the task requires customization or development of a specialized model.\\n\\nGiven that the description of the task is relatively broad and could imply varying levels of complexity depending on the context in which it is used, it is reasonable to regard it as more complex than straightforward tasks. \\n\\nThus, without additional context indicating a simple application of basic entity extraction, I will conclude that it can be considered complex.'},\n",
       " 'claude-3-5-sonnet-latest': {'value': 1,\n",
       "  'reason': \"Entity Extraction is a fundamental natural language processing task that involves:\\n\\n1. **Basic Concept**: The goal is to identify and extract specific entities (like names, dates, locations) from text, which is a straightforward objective.\\n\\n2. **Standard Techniques**: There are well-established methods and tools available for entity extraction, making implementation relatively straightforward.\\n\\n3. **Clear Process**: The task follows a linear process of analyzing text and identifying predefined entity types.\\n\\n4. **Accessible Tools**: Many pre-built libraries and APIs (like spaCy, NLTK) make entity extraction achievable without deep technical expertise.\\n\\n5. **Limited Scope**: The task description doesn't indicate any complex requirements or specialized adaptations.\\n\\nWhile entity extraction requires some technical knowledge, it doesn't involve complex multi-step reasoning or advanced expertise. The basic implementation is relatively straightforward, especially with modern tools and frameworks.\"}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexity_definition = (\n",
    "    \"A text is considered complex if it requires advanced knowledge \"\n",
    "    \"or expertise, contains multiple layered or specialized concepts, or \"\n",
    "    \"requires multi-step reasoning to understand or accomplish the described goal. \"\n",
    "    \"Otherwise, it's considered not complex.\"\n",
    ")\n",
    "\n",
    "complexity_test_node = MCT_Node(\n",
    "    id=\"complexity_test_node\",\n",
    "    label=\"comlexity_test_node\",\n",
    "    MCT_id=\"1\",\n",
    "    print_label=\"Entity Extraction\",\n",
    "    description=\"Entity Extraction\",\n",
    "    explanation=\"This step is crucial as it allows you to identify the key components (entities) and how they are related to each other, which is foundational for constructing a knowledge graph.\",\n",
    "    parentIds=[],\n",
    "    MCT_parent_id=None,\n",
    ")\n",
    "\n",
    "complexity = await criteria.run_complexity_evaluation_agent(\n",
    "    goal = \"Understanding Document Relationships\",\n",
    "    node = complexity_test_node,\n",
    "    model = \"\",\n",
    "    api_key = \"\",\n",
    "    complexity_definition=complexity_definition,\n",
    "    few_shot_examples=[\n",
    "        {\n",
    "            \"node\": MCT_Node(\n",
    "                id = \"example_node_1\",\n",
    "                label = \"Example Node\",\n",
    "                MCT_id = \"2\",\n",
    "                description = \"Named Entity Recognition\",\n",
    "                explanation = \"NER is a key part of understanding how documents relate because it helps identify and categorize things like people, places, organizations, and dates. By spotting these entities, NER makes it easier to see connections between documents. For example, if two documents mention \\\"Apple Inc.,\\\" they might be talking about the same topic. It also adds context, like figuring out if \\\"Paris\\\" refers to the city or a person, which helps in understanding the bigger picture. Plus, NER pulls out important details that let you compare or group documents, making it easier to analyze trends or build connections. In short, NER lays the groundwork for figuring out how documents are linked.\",\n",
    "                parentIds = [],\n",
    "                print_label = \"NER\",\n",
    "                MCT_parent_id = None,),\n",
    "            \"user_evaluation\": 1,\n",
    "            \n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai_client = OpenAI(api_key=open(\"../api_key\").read().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_def_toString(task, goal):\n",
    "    return task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_clients(model_enabled: list):\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    client_list = []\n",
    "    if openai_api_key and 'openai' in model_enabled:\n",
    "        model_client = OpenAIChatCompletionClient(\n",
    "            model='gpt-4o-mini',\n",
    "            api_key=openai_api_key,\n",
    "        )\n",
    "        client_list.append(model_client)\n",
    "    if anthropic_api_key and 'anthropic' in model_enabled:\n",
    "        sk_client = AnthropicChatCompletion(\n",
    "        ai_model_id=\"claude-3-5-sonnet-20241022\",\n",
    "        api_key=anthropic_api_key,service_id=\"my-service-id\",  # Optional; for targeting specific services within Semantic Kernel\n",
    "        )\n",
    "        settings = AnthropicChatPromptExecutionSettings(\n",
    "            temperature=0.2,\n",
    "        )\n",
    "\n",
    "        model_client = SKChatCompletionAdapter(\n",
    "            sk_client,\n",
    "            kernel=Kernel(memory=NullMemory()),\n",
    "            prompt_settings=settings,\n",
    "            model_info={\n",
    "                \"function_calling\": True,\n",
    "                \"json_output\": True,\n",
    "                \"vision\": True,\n",
    "                \"family\": ModelFamily.CLAUDE_3_5_SONNET,\n",
    "            },\n",
    "        )\n",
    "        client_list.append(model_client)\n",
    "    return client_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an AI assistant created by Anthropic, and the capital of France is Paris!!!\n"
     ]
    }
   ],
   "source": [
    "client = get_model_clients(['anthropic'])[0]\n",
    "agent = AssistantAgent(\n",
    "    name=\"test\",\n",
    "    model_client=client,\n",
    "    system_message=\"You are a helpful agent. You answer question with three exclamation marks at the end.\"\n",
    ")\n",
    "response = await agent.on_messages(\n",
    "    [TextMessage(content=\"Who are you and what is the capital of France?\", source=\"user\")],\n",
    "    cancellation_token=CancellationToken(),\n",
    ")\n",
    "print(response.chat_message.content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_complexity_evaluation_agent(\n",
    "    goal: str,\n",
    "    node: \"MCT_Node\",\n",
    "    model: str,\n",
    "    api_key: str,\n",
    "    complexity_definition: str,\n",
    "    few_shot_examples: list[dict],\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the complexity evaluation agent to evaluate whether the node is complex.\n",
    "    Args:\n",
    "        goal: The final task goal. (not actually used in the evaluation)\n",
    "        node: The node to evaluate.\n",
    "        model: The model to use for evaluation.\n",
    "        api_key: The API key for the model.\n",
    "        complexity_definition: The definition of complexity.\n",
    "        few_shot_examples: Few-shot examples for the evaluation. (optional)\n",
    "    \"\"\"\n",
    "\n",
    "    model_client = OpenAIChatCompletionClient(\n",
    "        model=model,\n",
    "        api_key=api_key,\n",
    "    )\n",
    "\n",
    "    complexity_evaluation_agent = AssistantAgent(\n",
    "        name=\"complexity_evaluation_agent\",\n",
    "        model_client=model_client,\n",
    "        # temperature=0.5,\n",
    "        system_message=f\"\"\"You are a text complexity evaluator. The user will provide some text that describes a task.\n",
    "Your job is to evaluate whether the text is 'complex' or 'not complex' based on the following definition:\n",
    "{complexity_definition}\n",
    "\n",
    "You must output your reasoning in a <REASONING>...</REASONING> block, then provide your final decision \n",
    "in a <RESULT>...</RESULT> block. The <RESULT> block must contain EXACTLY \"Yes\" or \"No\" (nothing else).\n",
    "\n",
    "Example format:\n",
    "<REASONING>This is my reasoning about complexity.</REASONING>\n",
    "<RESULT>Yes</RESULT>\n",
    "\"\"\",\n",
    "    )\n",
    "\n",
    "    few_shot_messages = []\n",
    "    if len(few_shot_examples) > 0:\n",
    "        for example in few_shot_examples:\n",
    "            example_reasoning = example['user_reasoning']\n",
    "            example_evaluation = example['user_evaluation']\n",
    "            few_shot_messages.append(\n",
    "                TextMessage(\n",
    "                    content=task_def_toString(\n",
    "                        # MCT_Node.model_validate(example[\"node\"]), goal\n",
    "                        example[\"node\"], goal\n",
    "                    ),\n",
    "                    source=\"user\",\n",
    "                )\n",
    "            )\n",
    "            few_shot_messages.append(\n",
    "                TextMessage(\n",
    "                    content=(\n",
    "                        f\"<REASONING>{example_reasoning}</REASONING>\\n\"\n",
    "                        f\"<RESULT>{'Yes' if example_evaluation else 'No'}</RESULT>\"\n",
    "                    ),\n",
    "                    source=\"assistant\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "    user_message = task_def_toString(node, goal)\n",
    "    messages = few_shot_messages + [TextMessage(content=user_message, source=\"user\")]\n",
    "\n",
    "    response = await complexity_evaluation_agent.on_messages(\n",
    "        messages,\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "\n",
    "    result_text = response.chat_message.content.strip()\n",
    "\n",
    "    reasoning_match = re.search(r\"<REASONING>(.*?)</REASONING>\", result_text, re.DOTALL)\n",
    "    reasoning = reasoning_match.group(1).strip() if reasoning_match else \"\"\n",
    "\n",
    "    result_match = re.search(r\"<RESULT>(.*?)</RESULT>\", result_text, re.DOTALL)\n",
    "    final_result = result_match.group(1).strip() if result_match else \"No\"\n",
    "\n",
    "    complexity_value = 1 if final_result == \"Yes\" else 0 if final_result == \"No\" else -1\n",
    "\n",
    "    # save_json(\n",
    "    #     {\n",
    "    #         \"system_message\": complexity_evaluation_agent._system_messages[0].content,\n",
    "    #         \"few_shot_messages\": list(\n",
    "    #             map(lambda m: m.source + \": \" + m.content, few_shot_messages)\n",
    "    #         ),\n",
    "    #         \"response\": result_text,\n",
    "    #     },\n",
    "    #     \"complexity_evaluation.json\",\n",
    "    # )\n",
    "\n",
    "    print(reasoning)\n",
    "\n",
    "    return complexity_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_coherence_evaluation_agent(\n",
    "    goal: str,\n",
    "    parent_node: \"MCT_Node\",\n",
    "    child_node: \"MCT_Node\",\n",
    "    model: str,\n",
    "    api_key: str,\n",
    "    coherence_definition: str,\n",
    "    few_shot_examples: list[dict],\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the coherence evaluation agent to evaluate whether the child node is coherent with the parent node.\n",
    "    Args:\n",
    "        goal: The final task goal. (not actually used in the evaluation)\n",
    "        parent_node: The parent node.\n",
    "        child_node: The child node. (the node to evaluate)\n",
    "        model: The model to use for evaluation.\n",
    "        api_key: The API key for the model.\n",
    "        coherence_definition: The definition of coherence.\n",
    "        few_shot_examples: Few-shot examples for the evaluation. (optional)\n",
    "    \"\"\"\n",
    "\n",
    "    model_client = OpenAIChatCompletionClient(\n",
    "        model=model,\n",
    "        api_key=api_key,\n",
    "    )\n",
    "\n",
    "    coherence_evaluation_agent = AssistantAgent(\n",
    "        name=\"coherence_evaluation_agent\",\n",
    "        model_client=model_client,\n",
    "        # temperature=0.5,\n",
    "        system_message=f\"\"\"You are a coherence evaluator. \n",
    "You will be given two parts of a sequence: a parent part and a child part.\n",
    "Evaluate whether the child part logically or thematically follows from the parent part \n",
    "according to the following definition of coherence:\n",
    "{coherence_definition}\n",
    "\n",
    "You must output your reasoning in a <REASONING>...</REASONING> block, \n",
    "then provide your final decision in a <RESULT>...</RESULT> block. \n",
    "The <RESULT> block must contain EXACTLY \"Yes\" or \"No\" (nothing else).\n",
    "\n",
    "Example format:\n",
    "<REASONING>This is my reasoning about coherence.</REASONING>\n",
    "<RESULT>Yes</RESULT>\n",
    "\"\"\",\n",
    "    )\n",
    "\n",
    "    def user_message_generator(_parent_node, _child_node):\n",
    "        return \"\"\"\n",
    "        - Parent Part: {parent_part}\n",
    "        - Child Part: {child_part}\n",
    "        \"\"\".format(\n",
    "            parent_part=task_def_toString(_parent_node, goal),\n",
    "            child_part=task_def_toString(_child_node, goal),\n",
    "        )\n",
    "\n",
    "    few_shot_messages = []\n",
    "    if len(few_shot_examples) > 0:\n",
    "        for example in few_shot_examples:\n",
    "            # example_parent = MCT_Node.model_validate(example[\"parent_node\"])\n",
    "            # example_child = MCT_Node.model_validate(example[\"node\"])\n",
    "            example_parent = example[\"node\"]\n",
    "            example_child = example[\"node\"]\n",
    "            example_reasoning = example[\"user_reasoning\"]\n",
    "            example_eval = example[\"user_evaluation\"]\n",
    "\n",
    "            few_shot_messages.append(\n",
    "                TextMessage(\n",
    "                    content=user_message_generator(example_parent, example_child),\n",
    "                    source=\"user\",\n",
    "                )\n",
    "            )\n",
    "            few_shot_messages.append(\n",
    "                TextMessage(\n",
    "                    content=(\n",
    "                        f\"<REASONING>{example_reasoning}</REASONING>\\n\"\n",
    "                        f\"<RESULT>{'Yes' if example_eval else 'No'}</RESULT>\"\n",
    "                    ),\n",
    "                    source=\"assistant\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "    user_message = user_message_generator(parent_node, child_node)\n",
    "    messages = few_shot_messages + [TextMessage(content=user_message, source=\"user\")]\n",
    "\n",
    "    response = await coherence_evaluation_agent.on_messages(\n",
    "        messages,\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "\n",
    "    result_text = response.chat_message.content.strip()\n",
    "\n",
    "    reasoning_match = re.search(r\"<REASONING>(.*?)</REASONING>\", result_text, re.DOTALL)\n",
    "    reasoning = reasoning_match.group(1).strip() if reasoning_match else \"\"\n",
    "\n",
    "    result_match = re.search(r\"<RESULT>(.*?)</RESULT>\", result_text, re.DOTALL)\n",
    "    final_result = result_match.group(1).strip() if result_match else \"No\"\n",
    "\n",
    "    coherence_value = 1 if final_result == \"Yes\" else 0 if final_result == \"No\" else -1\n",
    "\n",
    "    # save_json(\n",
    "    #     {\n",
    "    #         \"system_message\": coherence_evaluation_agent._system_messages[0].content,\n",
    "    #         \"few_shot_messages\": list(\n",
    "    #             map(lambda m: m.source + \": \" + m.content, few_shot_messages)\n",
    "    #         ),\n",
    "    #         \"response\": result,\n",
    "    #     },\n",
    "    #     \"coherence_evaluation.json\",\n",
    "    # )\n",
    "\n",
    "    print(reasoning)\n",
    "\n",
    "    return coherence_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_importance_evaluation_agent(\n",
    "    goal: str,\n",
    "    node: \"MCT_Node\", # MCT_Node\n",
    "    model: str,\n",
    "    api_key: str,\n",
    "    importance_definition: str,\n",
    "    few_shot_examples: list[dict],\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the importance evaluation agent to evaluate whether the node is important.\n",
    "    Args:\n",
    "        goal: The final task goal. (necessary for the evaluation)\n",
    "        node: The node to evaluate.\n",
    "        model: The model to use for evaluation.\n",
    "        api_key: The API key for the model.\n",
    "        importance_definition: The definition of importance.\n",
    "        few_shot_examples: Few-shot examples for the evaluation. (optional)\n",
    "    \"\"\"\n",
    "\n",
    "    model_client = OpenAIChatCompletionClient(\n",
    "        model=model,\n",
    "        api_key=api_key,\n",
    "    )\n",
    "\n",
    "    importance_evaluation_agent = AssistantAgent(\n",
    "        name=\"importance_evaluation_agent\",\n",
    "        model_client=model_client,\n",
    "        # temperature=0.5,\n",
    "        system_message=f\"\"\"You are an importance evaluator. \n",
    "You will be given a final task goal and a subtask description.\n",
    "Evaluate whether the subtask is important using the following definition:\n",
    "{importance_definition}\n",
    "\n",
    "You must output your reasoning in a <REASONING>...</REASONING> block, then provide your final decision \n",
    "in a <RESULT>...</RESULT> block. The <RESULT> block must contain EXACTLY \"Yes\" or \"No\" (nothing else).\n",
    "\n",
    "Example format:\n",
    "<REASONING>This is my reasoning about importance.</REASONING>\n",
    "<RESULT>Yes/No</RESULT>\n",
    "\"\"\",\n",
    "    )\n",
    "\n",
    "    def user_message_generator(_goal, _node):\n",
    "        return (\n",
    "            f\"- A final task goal: {_goal}\\n\"\n",
    "            f\"- A subtask description: {task_def_toString(_node, _goal)}\"\n",
    "        )\n",
    "\n",
    "    few_shot_messages = []\n",
    "    if len(few_shot_examples) > 0:\n",
    "        for example in few_shot_examples:\n",
    "            example_reasoning = example[\"user_reasoning\"]\n",
    "            example_evaluation = example[\"user_evaluation\"]\n",
    "            few_shot_messages.append(\n",
    "                TextMessage(\n",
    "                    content=user_message_generator(goal, example[\"node\"]),\n",
    "                    source=\"user\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            few_shot_messages.append(\n",
    "                TextMessage(\n",
    "                    content=(\n",
    "                        f\"<REASONING>{example_reasoning}</REASONING>\\n\"\n",
    "                        f\"<RESULT>{'Yes' if example_evaluation else 'No'}</RESULT>\"\n",
    "                    ),\n",
    "                    source=\"assistant\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "    user_message = user_message_generator(goal, node)\n",
    "    messages = few_shot_messages + [TextMessage(content=user_message, source=\"user\")]\n",
    "\n",
    "    response = await importance_evaluation_agent.on_messages(\n",
    "        messages,\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "\n",
    "    result_text = response.chat_message.content.strip()\n",
    "\n",
    "    reasoning_match = re.search(r\"<REASONING>(.*?)</REASONING>\", result_text, re.DOTALL)\n",
    "    reasoning = reasoning_match.group(1).strip() if reasoning_match else \"\"\n",
    "\n",
    "    result_match = re.search(r\"<RESULT>(.*?)</RESULT>\", result_text, re.DOTALL)\n",
    "    final_result = result_match.group(1).strip() if result_match else \"No\"\n",
    "\n",
    "    importance_value = 1 if final_result == \"Yes\" else 0 if final_result == \"No\" else -1\n",
    "\n",
    "    # save_json(\n",
    "    #     {\n",
    "    #         \"system_message\": complexity_evaluation_agent._system_messages[0].content,\n",
    "    #         \"few_shot_messages\": list(\n",
    "    #             map(lambda m: m.source + \": \" + m.content, few_shot_messages)\n",
    "    #         ),\n",
    "    #         \"response\": result,\n",
    "    #     },\n",
    "    #     \"complexity_evaluation.json\",\n",
    "    # )\n",
    "\n",
    "    print(reasoning)\n",
    "\n",
    "    return importance_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexity = await run_complexity_evaluation_agent(\n",
    "    text = 'This step is crucial as it allows you to identify the key components (entities) and how they are related to each other, which is foundational for constructing a knowledge graph.',\n",
    "    model = 'gpt-4o-mini',\n",
    "    api_key=open(\"../api_key\").read().strip()\n",
    ")\n",
    "complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence = await run_coherence_evaluation_agent(\n",
    "    parent_part = 'This step is crucial as it allows you to identify the key components (entities) and how they are related to each other, which is foundational for constructing a knowledge graph.',\n",
    "    child_part = 'This step is crucial as it allows you to identify the key components (entities) and how they are related to each other, which is foundational for constructing a knowledge graph.',\n",
    "    model = 'gpt-4o-mini',\n",
    "    api_key=open(\"../api_key\").read().strip()\n",
    ")\n",
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = await run_importance_evaluation_agent(\n",
    "    final_goal = \"Entity Extraction\",\n",
    "    subtask_description = \"This step is crucial as it allows you to identify the key components (entities) and how they are related to each other, which is foundational for constructing a knowledge graph.\",\n",
    "    model = 'gpt-4o-mini',\n",
    "    api_key=open(\"../api_key\").read().strip()\n",
    ")\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0.0\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import asyncio\n",
    "async def run_all_evaluations(goal: str, node_str: str, parent_node_str: str, model: str, api_key: str, evaluations: list=[]):\n",
    "    tasks = [\n",
    "        run_complexity_evaluation_agent(text=node_str, model=model, api_key=api_key),\n",
    "        run_coherence_evaluation_agent(parent_part=parent_node_str, child_part=node_str, model=model, api_key=api_key),\n",
    "        run_importance_evaluation_agent(final_goal=goal, subtask_description=node_str, model=model, api_key=api_key),\n",
    "    ]\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "goal = \"I want to construct a knowledge graph from a dataset of Wikipedia articles.\"\n",
    "node_str = \"\"\"Task: Extract Entities\n",
    "            Description: Identify and extract relevant entities from the collection of documents.\"\"\"\n",
    "parent_node_str =  \"\"\"Task: Root Node\n",
    "            Description: Start of the process.\"\"\"\n",
    "model = \"gpt-4o-mini\"\n",
    "api_key = open(\"../api_key\").read().strip()\n",
    "[a, b, c] = await run_all_evaluations(goal, node_str, parent_node_str, model, api_key)\n",
    "print(a, b, c, (a+b+c)/3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a text complexity evaluator. The user will provide some text that describes a task.\\nYour job is to evaluate whether the text is \\'complex\\' or \\'not complex\\' based on the following definition:\\n(\"A text is considered complex if it requires advanced knowledge or expertise, contains multiple layered or specialized concepts, or requires multi-step reasoning to understand or accomplish the described goal. Otherwise, it\\'s considered not complex.\",)\\n\\nIf the text meets the complexity definition, respond with:\\n\"Yes\"\\n\\nOtherwise, respond with:\\n\"No\"\\n\\nOutput must be EXACTLY one of these words, with no additional formatting, punctuation, or explanation.\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexity_definition: str = (\n",
    "        \"A text is considered complex if it requires advanced knowledge \"\n",
    "        \"or expertise, contains multiple layered or specialized concepts, or \"\n",
    "        \"requires multi-step reasoning to understand or accomplish the described goal. \"\n",
    "        \"Otherwise, it's considered not complex.\"\n",
    "    ),\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "        model=model,\n",
    "        api_key=api_key,\n",
    "    )\n",
    "complexity_evaluation_agent = AssistantAgent(\n",
    "        name=\"complexity_evaluation_agent\",\n",
    "        model_client=model_client,\n",
    "        # temperature=0.5,\n",
    "        system_message=f\"\"\"You are a text complexity evaluator. The user will provide some text that describes a task.\n",
    "Your job is to evaluate whether the text is 'complex' or 'not complex' based on the following definition:\n",
    "{complexity_definition}\n",
    "\n",
    "If the text meets the complexity definition, respond with:\n",
    "\"Yes\"\n",
    "\n",
    "Otherwise, respond with:\n",
    "\"No\"\n",
    "\n",
    "Output must be EXACTLY one of these words, with no additional formatting, punctuation, or explanation.\n",
    "\"\"\",\n",
    "    )\n",
    "complexity_evaluation_agent._system_messages[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text requires some understanding of knowledge graphs and the relationship between entities within that context, suggesting a need for specialized knowledge in data representation or information science. Identifying key components and their relationships also implies a level of analysis that entails multi-step reasoning. Therefore, this text involves layered concepts and necessitates advanced understanding, making it complex.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexity_definition = (\n",
    "    \"A text is considered complex if it requires advanced knowledge \"\n",
    "    \"or expertise, contains multiple layered or specialized concepts, or \"\n",
    "    \"requires multi-step reasoning to understand or accomplish the described goal. \"\n",
    "    \"Otherwise, it's considered not complex.\"\n",
    ")\n",
    "\n",
    "complexity = await run_complexity_evaluation_agent(\n",
    "    goal = \"Understanding Document Relationships\",\n",
    "    node = \"This step is crucial as it allows you to identify the key components (entities) and how they are related to each other, which is foundational for constructing a knowledge graph.\",\n",
    "    model = \"gpt-4o-mini\",\n",
    "    api_key = open(\"../../api_key\").read().strip(),\n",
    "    complexity_definition=complexity_definition,\n",
    "    few_shot_examples=[]\n",
    ")\n",
    "\n",
    "complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Parent Part discusses \"Entity Extraction,\" which typically involves identifying and categorizing key entities from a given text. The Child Part, \"Entity Relationship Tree Construction,\" logically follows as it suggests a subsequent step where the entities extracted are organized into a structured format that illustrates the relationships between them. This shows a progression in data processing, where the foundational work of entity extraction leads naturally to the construction of relationships between those entities. There is no contradiction and the concepts are related within the same domain of information processing.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_definition = (\n",
    "    \"Two text pieces are considered coherent in a sequence if the second \"\n",
    "    \"logically or thematically follows from the first, maintains consistency with it, \"\n",
    "    \"and does not present a contradictory or unrelated concept.\"\n",
    ")\n",
    "\n",
    "coherence = await run_coherence_evaluation_agent(\n",
    "    goal = \"Understanding Document Relationships\",\n",
    "    parent_node = \"Entity Extraction\",\n",
    "    child_node = \"Entity Relationship Tree Construction\",\n",
    "    model = \"gpt-4o-mini\",\n",
    "    api_key=open(\"../../api_key\").read().strip(),\n",
    "    coherence_definition=coherence_definition,\n",
    "    few_shot_examples=[]\n",
    ")\n",
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity extraction is critical for understanding document relationships as it involves identifying and classifying key components and entities within the documents. This information is essential for establishing connections and understanding how different documents relate to each other. Without entity extraction, it would be challenging to analyze the relationships accurately, making it a fundamental part of achieving the overall goal. Therefore, this subtask is important.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_definition: str = (\n",
    "    (\n",
    "        \"A subtask is considered important if it is critical, essential, \"\n",
    "        \"or significantly beneficial to achieving the final goal. If it is tangential, \"\n",
    "        \"optional, or has minimal impact, then it is not important.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "importance = await run_importance_evaluation_agent(\n",
    "    goal = \"Understanding Document Relationships\",\n",
    "    node = \"Entity Extraction\",\n",
    "    model = \"gpt-4o-mini\",\n",
    "    api_key=open(\"../../api_key\").read().strip(),\n",
    "    importance_definition=importance_definition,\n",
    "    few_shot_examples=[]\n",
    ")\n",
    "importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task-decomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
