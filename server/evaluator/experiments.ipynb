{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samytlee/opt/anaconda3/envs/taskdecomposition/lib/python3.13/site-packages/pydantic/_internal/_model_construction.py:25: RuntimeWarning: coroutine 'run_importance_evaluation_agent' was never awaited\n",
      "  from ._generate_schema import GenerateSchema\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/samytlee/opt/anaconda3/envs/taskdecomposition/lib/python3.13/site-packages/pydantic/_internal/_model_construction.py:25: RuntimeWarning: coroutine 'run_coherence_evaluation_agent' was never awaited\n",
      "  from ._generate_schema import GenerateSchema\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/samytlee/opt/anaconda3/envs/taskdecomposition/lib/python3.13/site-packages/pydantic/_internal/_model_construction.py:25: RuntimeWarning: coroutine 'run_complexity_evaluation_agent' was never awaited\n",
      "  from ._generate_schema import GenerateSchema\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai_client = OpenAI(api_key=open(\"../api_key\").read().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL\n",
    "\n",
    "async def run_complexity_evaluation_agent(\n",
    "    text: str,\n",
    "    model: str,\n",
    "    api_key: str,\n",
    "    complexity_definition: str = (\n",
    "        \"A text is considered complex if it requires advanced knowledge \"\n",
    "        \"or expertise, contains multiple layered or specialized concepts, or \"\n",
    "        \"requires multi-step reasoning to understand or accomplish the described goal. \"\n",
    "        \"Otherwise, it's considered not complex.\"\n",
    "    ),\n",
    "):\n",
    "    \n",
    "    model_client = OpenAIChatCompletionClient(\n",
    "        model=model,\n",
    "        api_key=api_key,\n",
    "    )\n",
    "    \n",
    "    complexity_evaluation_agent = AssistantAgent(\n",
    "        name=\"complexity_evaluation_agent\",\n",
    "        model_client=model_client,\n",
    "        # temperature=0.5,\n",
    "        system_message=f\"\"\"You are a text complexity evaluator. The user will provide some text that describes a task.\n",
    "Your job is to evaluate whether the text is 'complex' or 'not complex' based on the following definition:\n",
    "{complexity_definition}\n",
    "\n",
    "If the text meets the complexity definition, respond with:\n",
    "\"Yes\"\n",
    "\n",
    "Otherwise, respond with:\n",
    "\"No\"\n",
    "\n",
    "Output must be EXACTLY one of these words, with no additional formatting, punctuation, or explanation.\n",
    "\"\"\",\n",
    "    )\n",
    "    \n",
    "    response = await complexity_evaluation_agent.on_messages(\n",
    "        [TextMessage(content=text, source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "\n",
    "    result = response.chat_message.content.strip()\n",
    "    return 1 if result == \"Yes\" else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_coherence_evaluation_agent(\n",
    "    parent_part: str,\n",
    "    child_part: str,\n",
    "    model: str,\n",
    "    api_key: str,\n",
    "    coherence_definition: str = (\n",
    "        \"Two text pieces are considered coherent in a sequence if the second \"\n",
    "        \"logically or thematically follows from the first, maintains consistency with it, \"\n",
    "        \"and does not present a contradictory or unrelated concept.\"\n",
    "    ),\n",
    "):\n",
    "    \n",
    "    model_client = OpenAIChatCompletionClient(\n",
    "        model=model,\n",
    "        api_key=api_key,\n",
    "    )\n",
    "    \n",
    "    coherence_evaluation_agent = AssistantAgent(\n",
    "        name=\"coherence_evaluation_agent\",\n",
    "        model_client=model_client,\n",
    "        # temperature=0.5,\n",
    "        system_message=f\"\"\"You are a coherence evaluator. You will be given two parts of a sequence:\n",
    "- Parent Part: {parent_part}\n",
    "- Child Part: {child_part}\n",
    "\n",
    "Evaluate whether Child Part logically or thematically follows from Parent Part, consistent with the following definition of coherence:\n",
    "{coherence_definition}\n",
    "\n",
    "If they are coherent, respond with:\n",
    "\"Yes\"\n",
    "\n",
    "If they are not coherent, respond with:\n",
    "\"No\"\n",
    "\n",
    "Output must be EXACTLY one of these words, with no additional formatting, punctuation, or explanation.\n",
    "\"\"\"\n",
    "    )\n",
    "    \n",
    "    response = await coherence_evaluation_agent.on_messages(\n",
    "        [TextMessage(content=\"\", source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "    \n",
    "    result = response.chat_message.content.strip()\n",
    "    \n",
    "    return 1 if result == \"Yes\" else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_importance_evaluation_agent(\n",
    "    final_goal: str,\n",
    "    subtask_description: str,\n",
    "    model: str,\n",
    "    api_key: str,\n",
    "    importance_definition: str = (\n",
    "        \"A subtask is considered important if it is critical, essential, \"\n",
    "        \"or significantly beneficial to achieving the final goal. If it is tangential, \"\n",
    "        \"optional, or has minimal impact, then it is not important.\"\n",
    "    ),\n",
    "):\n",
    "    \n",
    "    model_client = OpenAIChatCompletionClient(\n",
    "        model=model,\n",
    "        api_key=api_key,\n",
    "    )\n",
    "    \n",
    "    importance_evaluation_agent = AssistantAgent(\n",
    "        name=\"importance_evaluation_agent\",\n",
    "        model_client=model_client,\n",
    "        # temperature=0.5,\n",
    "        system_message=f\"\"\"You are an importance evaluator. You will be given:\n",
    "- A final task goal: {final_goal}\n",
    "- A subtask description: {subtask_description}\n",
    "\n",
    "Evaluate whether the subtask is important using the following definition:\n",
    "{importance_definition}\n",
    "\n",
    "If they are important, respond with:\n",
    "\"Yes\"\n",
    "\n",
    "Otherwise, respond with:\n",
    "\"No\"\n",
    "\n",
    "Output must be EXACTLY one of these words, with no additional formatting, punctuation, or explanation.\n",
    "\"\"\")\n",
    "    \n",
    "    response = await importance_evaluation_agent.on_messages(\n",
    "        [TextMessage(content=\"\", source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "    \n",
    "    result = response.chat_message.content.strip()\n",
    "    return 1 if result == \"Yes\" else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexity = await run_complexity_evaluation_agent(\n",
    "    text = 'This step is crucial as it allows you to identify the key components (entities) and how they are related to each other, which is foundational for constructing a knowledge graph.',\n",
    "    model = 'gpt-4o-mini',\n",
    "    api_key=open(\"../api_key\").read().strip()\n",
    ")\n",
    "complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence = await run_coherence_evaluation_agent(\n",
    "    parent_part = 'This step is crucial as it allows you to identify the key components (entities) and how they are related to each other, which is foundational for constructing a knowledge graph.',\n",
    "    child_part = 'This step is crucial as it allows you to identify the key components (entities) and how they are related to each other, which is foundational for constructing a knowledge graph.',\n",
    "    model = 'gpt-4o-mini',\n",
    "    api_key=open(\"../api_key\").read().strip()\n",
    ")\n",
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = await run_importance_evaluation_agent(\n",
    "    final_goal = \"Entity Extraction\",\n",
    "    subtask_description = \"This step is crucial as it allows you to identify the key components (entities) and how they are related to each other, which is foundational for constructing a knowledge graph.\",\n",
    "    model = 'gpt-4o-mini',\n",
    "    api_key=open(\"../api_key\").read().strip()\n",
    ")\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0.0\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import asyncio\n",
    "async def run_all_evaluations(goal: str, node_str: str, parent_node_str: str, model: str, api_key: str, evaluations: list=[]):\n",
    "    tasks = [\n",
    "        run_complexity_evaluation_agent(text=node_str, model=model, api_key=api_key),\n",
    "        run_coherence_evaluation_agent(parent_part=parent_node_str, child_part=node_str, model=model, api_key=api_key),\n",
    "        run_importance_evaluation_agent(final_goal=goal, subtask_description=node_str, model=model, api_key=api_key),\n",
    "    ]\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "goal = \"I want to construct a knowledge graph from a dataset of Wikipedia articles.\"\n",
    "node_str = \"\"\"Task: Extract Entities\n",
    "            Description: Identify and extract relevant entities from the collection of documents.\"\"\"\n",
    "parent_node_str =  \"\"\"Task: Root Node\n",
    "            Description: Start of the process.\"\"\"\n",
    "model = \"gpt-4o-mini\"\n",
    "api_key = open(\"../api_key\").read().strip()\n",
    "[a, b, c] = await run_all_evaluations(goal, node_str, parent_node_str, model, api_key)\n",
    "print(a, b, c, (a+b+c)/3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a text complexity evaluator. The user will provide some text that describes a task.\\nYour job is to evaluate whether the text is \\'complex\\' or \\'not complex\\' based on the following definition:\\n(\"A text is considered complex if it requires advanced knowledge or expertise, contains multiple layered or specialized concepts, or requires multi-step reasoning to understand or accomplish the described goal. Otherwise, it\\'s considered not complex.\",)\\n\\nIf the text meets the complexity definition, respond with:\\n\"Yes\"\\n\\nOtherwise, respond with:\\n\"No\"\\n\\nOutput must be EXACTLY one of these words, with no additional formatting, punctuation, or explanation.\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexity_definition: str = (\n",
    "        \"A text is considered complex if it requires advanced knowledge \"\n",
    "        \"or expertise, contains multiple layered or specialized concepts, or \"\n",
    "        \"requires multi-step reasoning to understand or accomplish the described goal. \"\n",
    "        \"Otherwise, it's considered not complex.\"\n",
    "    ),\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "        model=model,\n",
    "        api_key=api_key,\n",
    "    )\n",
    "complexity_evaluation_agent = AssistantAgent(\n",
    "        name=\"complexity_evaluation_agent\",\n",
    "        model_client=model_client,\n",
    "        # temperature=0.5,\n",
    "        system_message=f\"\"\"You are a text complexity evaluator. The user will provide some text that describes a task.\n",
    "Your job is to evaluate whether the text is 'complex' or 'not complex' based on the following definition:\n",
    "{complexity_definition}\n",
    "\n",
    "If the text meets the complexity definition, respond with:\n",
    "\"Yes\"\n",
    "\n",
    "Otherwise, respond with:\n",
    "\"No\"\n",
    "\n",
    "Output must be EXACTLY one of these words, with no additional formatting, punctuation, or explanation.\n",
    "\"\"\",\n",
    "    )\n",
    "complexity_evaluation_agent._system_messages[0].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taskdecomposition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
